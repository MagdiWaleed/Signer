{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "586a8aa7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:00.701694Z",
     "iopub.status.busy": "2025-07-01T05:43:00.701440Z",
     "iopub.status.idle": "2025-07-01T05:43:07.752434Z",
     "shell.execute_reply": "2025-07-01T05:43:07.751863Z",
     "shell.execute_reply.started": "2025-07-01T05:43:00.701669Z"
    },
    "papermill": {
     "duration": 24.539138,
     "end_time": "2025-06-28T23:46:39.937168",
     "exception": false,
     "start_time": "2025-06-28T23:46:15.398030",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-01 05:43:02.755119: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1751348582.778083     235 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1751348582.785308     235 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import torch\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import torchvision.transforms.functional as TransformerF\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms, models\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "from copy import deepcopy\n",
    "import json\n",
    "import time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f79e6205",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:07.948569Z",
     "iopub.status.busy": "2025-07-01T05:43:07.948353Z",
     "iopub.status.idle": "2025-07-01T05:43:09.966889Z",
     "shell.execute_reply": "2025-07-01T05:43:09.966270Z",
     "shell.execute_reply.started": "2025-07-01T05:43:07.948544Z"
    },
    "papermill": {
     "duration": 13.192312,
     "end_time": "2025-06-28T23:46:53.376089",
     "exception": false,
     "start_time": "2025-06-28T23:46:40.183777",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3243"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "CHECKPOINT_PATH = \"/kaggle/input/attention-based-multi-module-fusion/data\"\n",
    "BASE_PATH = '/kaggle/input'\n",
    "m = [\n",
    "    \"wait\",\n",
    "    \"bring\",\n",
    "    \"friend\",\n",
    "    \"good\",\n",
    "    \"get_well\",\n",
    "    \"get-well\",\n",
    "    \"thanks\",\n",
    "    \"who\",\n",
    "    \"where\",\n",
    "    \"why\",\n",
    "    \"time\",\n",
    "    \"tomorrow\",\n",
    "    \"always\",\n",
    "    \"apologize\",\n",
    "    \"goodbye\",\n",
    "    \"single\",\n",
    "    \"same\",\n",
    "    \"hurry\",\n",
    "    \"belt\",\n",
    "    \"congratulation\",\n",
    "    \"police\",\n",
    "    \"single\",\n",
    "    \"accident\",\n",
    "    \"bed\",\n",
    "    \"breakfast\",\n",
    "    \"forbidden\",\n",
    "    \"sibling\",\n",
    "    \"angle\",\n",
    "    \"glove\",\n",
    "    \"full\"\n",
    "        ]\n",
    "tester = []\n",
    "train_video_pathes = []\n",
    "train_labels = []\n",
    "for gloss in os.listdir(BASE_PATH):\n",
    "  if not gloss.__contains__(\"segmented\") :\n",
    "      continue\n",
    "  glossName = os.listdir(os.path.join(BASE_PATH,gloss))[0]\n",
    "  if glossName in m:\n",
    "    for video_path in os.listdir(os.path.join(BASE_PATH,gloss,glossName)):\n",
    "        files = os.listdir(os.path.join(BASE_PATH,gloss,glossName,video_path))\n",
    "        tester.append(video_path)\n",
    "        train_video_pathes.append([os.path.join(BASE_PATH,gloss,glossName,video_path,files[0]),os.path.join(BASE_PATH,gloss,glossName,video_path,files[1]),os.path.join(BASE_PATH,gloss,glossName,video_path,files[2])])\n",
    "        train_labels.append(glossName.lower())\n",
    "\n",
    "BASE_PATH = '/kaggle/input'\n",
    "for gloss in os.listdir(BASE_PATH):\n",
    "  if not gloss.endswith(\"-gloss\") or not gloss.split(\"-gloss\")[0] in m :  \n",
    "      continue\n",
    "  glossName = gloss.split(\"-\")[0]   \n",
    "  for video_path in os.listdir(os.path.join(BASE_PATH,gloss)):\n",
    "    if video_path.endswith(\"json\"):\n",
    "        continue\n",
    "    files = os.listdir(os.path.join(BASE_PATH,gloss,video_path))\n",
    "    tester.append(video_path)\n",
    "    train_video_pathes.append([os.path.join(BASE_PATH,gloss,video_path,files[0]),os.path.join(BASE_PATH,gloss,video_path,files[1]),os.path.join(BASE_PATH,gloss,video_path,files[2])])\n",
    "    train_labels.append(glossName.lower())\n",
    "\n",
    "test_video_pathes = []\n",
    "test_labels = []\n",
    "for t in range(1,6):\n",
    "    BASE_PATH = f'/kaggle/input/test-segmented-continue-part{t}-db/gloss'\n",
    "    for gloss in os.listdir(BASE_PATH):\n",
    "      if gloss in m:\n",
    "        for video_path in os.listdir(os.path.join(BASE_PATH,gloss)):\n",
    "            files = os.listdir(os.path.join(BASE_PATH,gloss,video_path))\n",
    "            test_video_pathes.append([os.path.join(BASE_PATH,gloss,video_path,files[0]),os.path.join(BASE_PATH,gloss,video_path,files[1]),os.path.join(BASE_PATH,gloss,video_path,files[2])])\n",
    "            test_labels.append(gloss.lower())\n",
    "len(train_video_pathes)\n",
    "\n",
    "# BASE_PATH = \"/kaggle/input/test-continue-part2-db/output\"\n",
    "# for gloss in os.listdir(BASE_PATH):\n",
    "#   if gloss in m:\n",
    "#     for video_path in os.listdir(os.path.join(BASE_PATH,gloss)):\n",
    "#         files = os.listdir(os.path.join(BASE_PATH,gloss,video_path))\n",
    "#         test_video_pathes.append([os.path.join(BASE_PATH,gloss,video_path,files[0]),os.path.join(BASE_PATH,gloss,video_path,files[1])])\n",
    "#         test_labels.append(gloss.lower())\n",
    "len(train_video_pathes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0f486f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:09.967712Z",
     "iopub.status.busy": "2025-07-01T05:43:09.967537Z",
     "iopub.status.idle": "2025-07-01T05:43:09.972617Z",
     "shell.execute_reply": "2025-07-01T05:43:09.972091Z",
     "shell.execute_reply.started": "2025-07-01T05:43:09.967698Z"
    },
    "papermill": {
     "duration": 0.011852,
     "end_time": "2025-06-28T23:46:53.394193",
     "exception": false,
     "start_time": "2025-06-28T23:46:53.382341",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 26)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(train_labels)),len(set(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5c660968",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:09.973522Z",
     "iopub.status.busy": "2025-07-01T05:43:09.973307Z",
     "iopub.status.idle": "2025-07-01T05:43:09.993965Z",
     "shell.execute_reply": "2025-07-01T05:43:09.993262Z",
     "shell.execute_reply.started": "2025-07-01T05:43:09.973490Z"
    },
    "papermill": {
     "duration": 0.015737,
     "end_time": "2025-06-28T23:46:53.415637",
     "exception": false,
     "start_time": "2025-06-28T23:46:53.399900",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3243 3243 179\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'bed': 127,\n",
       "  'single': 126,\n",
       "  'thanks': 126,\n",
       "  'accident': 125,\n",
       "  'get_well': 124,\n",
       "  'tomorrow': 117,\n",
       "  'hurry': 125,\n",
       "  'time': 123,\n",
       "  'apologize': 127,\n",
       "  'goodbye': 127,\n",
       "  'breakfast': 125,\n",
       "  'where': 127,\n",
       "  'who': 126,\n",
       "  'belt': 127,\n",
       "  'wait': 125,\n",
       "  'glove': 122,\n",
       "  'why': 127,\n",
       "  'forbidden': 123,\n",
       "  'same': 120,\n",
       "  'full': 127,\n",
       "  'friend': 121,\n",
       "  'police': 126,\n",
       "  'always': 123,\n",
       "  'bring': 124,\n",
       "  'sibling': 126,\n",
       "  'good': 127},\n",
       " {'bed': 8,\n",
       "  'single': 7,\n",
       "  'thanks': 8,\n",
       "  'accident': 5,\n",
       "  'get_well': 6,\n",
       "  'tomorrow': 7,\n",
       "  'hurry': 6,\n",
       "  'time': 7,\n",
       "  'apologize': 6,\n",
       "  'goodbye': 7,\n",
       "  'breakfast': 7,\n",
       "  'where': 8,\n",
       "  'who': 8,\n",
       "  'belt': 6,\n",
       "  'wait': 6,\n",
       "  'glove': 7,\n",
       "  'why': 6,\n",
       "  'forbidden': 7,\n",
       "  'same': 7,\n",
       "  'full': 8,\n",
       "  'friend': 6,\n",
       "  'police': 7,\n",
       "  'always': 8,\n",
       "  'bring': 8,\n",
       "  'sibling': 7,\n",
       "  'good': 6})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(tester),len(set(tester)),len(test_labels))\n",
    "train_dictanory = {t:0 for t in set(np.sort(train_labels))}\n",
    "test_dictanory = {t:0 for t in set(np.sort(test_labels))}\n",
    "for t in train_labels:\n",
    "    train_dictanory[t]+=1\n",
    "    \n",
    "for t in test_labels:\n",
    "    test_dictanory[t]+=1\n",
    "\n",
    "train_dictanory,test_dictanory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a83e1e",
   "metadata": {
    "_cell_guid": "c4bc09e2-3410-4599-89e1-b1ddb74f6b0b",
    "_uuid": "85ec740d-6454-4d1d-bea0-e93421746585",
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:09.994891Z",
     "iopub.status.busy": "2025-07-01T05:43:09.994655Z",
     "iopub.status.idle": "2025-07-01T05:43:10.009550Z",
     "shell.execute_reply": "2025-07-01T05:43:10.008856Z",
     "shell.execute_reply.started": "2025-07-01T05:43:09.994872Z"
    },
    "papermill": {
     "duration": 0.029452,
     "end_time": "2025-06-28T23:46:53.451103",
     "exception": false,
     "start_time": "2025-06-28T23:46:53.421651",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/utils/data/dataloader.py:624: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "train_dataset = VideoDataset(\n",
    "    train_video_pathes,\n",
    "   train_labels,\n",
    "  agumentation=True,temp_agumentation=False,getCropedImageToo=True\n",
    "    )\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=2,shuffle=True,\n",
    "    num_workers=8,  \n",
    "    pin_memory=True, \n",
    "    prefetch_factor=5,\n",
    "    timeout=60\n",
    "                              )\n",
    "test_dataset = VideoDataset(\n",
    "    test_video_pathes,\n",
    "    test_labels,getCropedImageToo=True\n",
    "    )\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=2,shuffle=True,\n",
    "     num_workers=4,  \n",
    "    pin_memory=True, \n",
    "    prefetch_factor=5,\n",
    "    timeout=60\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0b0cfa",
   "metadata": {
    "_cell_guid": "26ea7d98-b12c-47b4-86b5-320b9d945d54",
    "_uuid": "6cd7c2db-9dc2-443d-82ff-a83c15035091",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:10.104062Z",
     "iopub.status.busy": "2025-07-01T05:43:10.103828Z",
     "iopub.status.idle": "2025-07-01T05:43:10.136687Z",
     "shell.execute_reply": "2025-07-01T05:43:10.136014Z",
     "shell.execute_reply.started": "2025-07-01T05:43:10.104048Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.038554,
     "end_time": "2025-06-28T23:46:53.595364",
     "exception": false,
     "start_time": "2025-06-28T23:46:53.556810",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({0: 'accident',\n",
       "  1: 'always',\n",
       "  2: 'apologize',\n",
       "  3: 'bed',\n",
       "  4: 'belt',\n",
       "  5: 'breakfast',\n",
       "  6: 'bring',\n",
       "  7: 'forbidden',\n",
       "  8: 'friend',\n",
       "  9: 'full',\n",
       "  10: 'get_well',\n",
       "  11: 'glove',\n",
       "  12: 'good',\n",
       "  13: 'goodbye',\n",
       "  14: 'hurry',\n",
       "  15: 'police',\n",
       "  16: 'same',\n",
       "  17: 'sibling',\n",
       "  18: 'single',\n",
       "  19: 'thanks',\n",
       "  20: 'time',\n",
       "  21: 'tomorrow',\n",
       "  22: 'wait',\n",
       "  23: 'where',\n",
       "  24: 'who',\n",
       "  25: 'why'},\n",
       " {0: 'accident',\n",
       "  1: 'always',\n",
       "  2: 'apologize',\n",
       "  3: 'bed',\n",
       "  4: 'belt',\n",
       "  5: 'breakfast',\n",
       "  6: 'bring',\n",
       "  7: 'forbidden',\n",
       "  8: 'friend',\n",
       "  9: 'full',\n",
       "  10: 'get_well',\n",
       "  11: 'glove',\n",
       "  12: 'good',\n",
       "  13: 'goodbye',\n",
       "  14: 'hurry',\n",
       "  15: 'police',\n",
       "  16: 'same',\n",
       "  17: 'sibling',\n",
       "  18: 'single',\n",
       "  19: 'thanks',\n",
       "  20: 'time',\n",
       "  21: 'tomorrow',\n",
       "  22: 'wait',\n",
       "  23: 'where',\n",
       "  24: 'who',\n",
       "  25: 'why'})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{val:key for key,val in train_dataset.label_to_index.items()},{val:key for key,val in test_dataset.label_to_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39afefee-9cee-4c76-8ff3-ce9500050436",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:10.160154Z",
     "iopub.status.busy": "2025-07-01T05:43:10.159875Z",
     "iopub.status.idle": "2025-07-01T05:43:10.183160Z",
     "shell.execute_reply": "2025-07-01T05:43:10.182502Z",
     "shell.execute_reply.started": "2025-07-01T05:43:10.160131Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['data.json', 'checkpoint.pth']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(CHECKPOINT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf211bf",
   "metadata": {
    "_cell_guid": "2b7098eb-b328-4522-92e2-125c3eee33fc",
    "_uuid": "b79d0bd2-3280-426b-a2e8-5f858aa298ba",
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:10.183972Z",
     "iopub.status.busy": "2025-07-01T05:43:10.183764Z",
     "iopub.status.idle": "2025-07-01T05:43:23.929335Z",
     "shell.execute_reply": "2025-07-01T05:43:23.928468Z",
     "shell.execute_reply.started": "2025-07-01T05:43:10.183958Z"
    },
    "papermill": {
     "duration": 12.072946,
     "end_time": "2025-06-28T23:47:05.712964",
     "exception": false,
     "start_time": "2025-06-28T23:46:53.640018",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from Model import Model\n",
    "if not os.path.exists(os.path.join(CHECKPOINT_PATH,'checkpoint.pth')):\n",
    "    model = Model().to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=8e-05)\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',         \n",
    "        factor=0.5,         \n",
    "        patience=3,         \n",
    "        verbose=True        \n",
    "    )\n",
    "    \n",
    "    start_epoch= 0 \n",
    "    test_accuracy = 0\n",
    "else:\n",
    "    import torch\n",
    "    import gc\n",
    "    from torch import nn\n",
    "    \n",
    "    # 1. Force clean GPU memory\n",
    "    def clear_gpu_memory():\n",
    "        gc.collect()\n",
    "        torch.cuda.empty_cache()\n",
    "        torch.cuda.reset_peak_memory_stats()  # Reset memory tracking\n",
    "    \n",
    "    clear_gpu_memory()\n",
    "    \n",
    "    # 2. Load checkpoint differently\n",
    "    def load_checkpoint_safely(checkpoint_path, device):\n",
    "        # Load to CPU first\n",
    "        checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "        \n",
    "        # Create model on CPU\n",
    "        model = Model()  # Don't move to GPU yet\n",
    "        with open(os.path.join(CHECKPOINT_PATH,'data.json'), 'r') as file:\n",
    "            data = json.load(file)\n",
    "            \n",
    "        if 'best test accuracy' in data:\n",
    "            test_accuracy = data[\"best test accuracy\"]\n",
    "        else:\n",
    "            test_accuracy = 0\n",
    "         # Load state dict in eval mode (uses less memory)\n",
    "        model.eval()\n",
    "        model.load_state_dict(checkpoint['best_model_state_dict'])\n",
    "        \n",
    "        # Now move to GPU\n",
    "        model = model.to(device)\n",
    "        \n",
    "        # Create optimizer after model is on GPU\n",
    "        optimizer = torch.optim.AdamW(model.parameters(), lr=8e-05)\n",
    "        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "        \n",
    "        return {\n",
    "            'model': model,\n",
    "            'optimizer': optimizer,\n",
    "            'epoch': checkpoint['epoch'],\n",
    "            'scheduler_state': checkpoint.get('scheduler_state_dict', None)\n",
    "        },test_accuracy\n",
    "    \n",
    "\n",
    "    os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "    \n",
    "    # Load checkpoint\n",
    "    loaded, test_accuracy = load_checkpoint_safely(os.path.join(CHECKPOINT_PATH,'checkpoint.pth'), device)\n",
    "    \n",
    "    model = loaded['model']\n",
    "    optimizer = loaded['optimizer']\n",
    "    start_epoch = loaded['epoch']\n",
    "    \n",
    "    # Recreate scheduler\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "        optimizer,\n",
    "        mode='min',\n",
    "        factor=0.5,\n",
    "        patience=3,\n",
    "        verbose=True\n",
    "    )\n",
    "    \n",
    "    if loaded['scheduler_state'] is not None:\n",
    "        scheduler.load_state_dict(loaded['scheduler_state'])\n",
    "                \n",
    "classification_loss = nn.CrossEntropyLoss ()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "38d1817e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:23.930595Z",
     "iopub.status.busy": "2025-07-01T05:43:23.930327Z",
     "iopub.status.idle": "2025-07-01T05:43:23.934749Z",
     "shell.execute_reply": "2025-07-01T05:43:23.934163Z",
     "shell.execute_reply.started": "2025-07-01T05:43:23.930577Z"
    },
    "papermill": {
     "duration": 0.011884,
     "end_time": "2025-06-28T23:47:05.749582",
     "exception": false,
     "start_time": "2025-06-28T23:47:05.737698",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started epoch:  82\n",
      "test accuracy:  0.8938547486033519\n"
     ]
    }
   ],
   "source": [
    "print(\"started epoch: \", start_epoch)\n",
    "print(\"test accuracy: \",test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af878eb1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-01T05:43:23.956451Z",
     "iopub.status.busy": "2025-07-01T05:43:23.956199Z"
    },
    "papermill": {
     "duration": 37802.218421,
     "end_time": "2025-06-29T10:17:07.991917",
     "exception": false,
     "start_time": "2025-06-28T23:47:05.773496",
     "status": "completed"
    },
    "tags": [],
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from tools import train\n",
    "history = train(model,classification_loss_fn,epoch,train_loader,test_loader,scheduler,test_accuracy,CHECKPOINT_PATH,optimizer,device,train_dataset)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 7667745,
     "sourceId": 12178530,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7724798,
     "sourceId": 12258871,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7725668,
     "sourceId": 12260115,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7725671,
     "sourceId": 12260118,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7725682,
     "sourceId": 12260132,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7725687,
     "sourceId": 12260140,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726215,
     "sourceId": 12260915,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726520,
     "sourceId": 12261377,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726522,
     "sourceId": 12261380,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726526,
     "sourceId": 12261384,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726656,
     "sourceId": 12261656,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726704,
     "sourceId": 12261747,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726771,
     "sourceId": 12261881,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726829,
     "sourceId": 12261987,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726871,
     "sourceId": 12262089,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7726951,
     "sourceId": 12262209,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7727149,
     "sourceId": 12262511,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7727445,
     "sourceId": 12262969,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7727449,
     "sourceId": 12262977,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7727460,
     "sourceId": 12262990,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7727795,
     "sourceId": 12263485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7727943,
     "sourceId": 12263700,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7728115,
     "sourceId": 12263958,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7728313,
     "sourceId": 12264237,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7728549,
     "sourceId": 12264568,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7729656,
     "sourceId": 12266296,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7729885,
     "sourceId": 12266609,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7730094,
     "sourceId": 12267002,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7730298,
     "sourceId": 12267385,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7730512,
     "sourceId": 12267780,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7730748,
     "sourceId": 12268143,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7731234,
     "sourceId": 12268829,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7731476,
     "sourceId": 12269161,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7731717,
     "sourceId": 12269508,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7731992,
     "sourceId": 12269900,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7732211,
     "sourceId": 12270203,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7732444,
     "sourceId": 12270524,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7732697,
     "sourceId": 12270878,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7732951,
     "sourceId": 12271237,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7733171,
     "sourceId": 12271536,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7733995,
     "sourceId": 12272676,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7734139,
     "sourceId": 12272922,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7734271,
     "sourceId": 12273187,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7734362,
     "sourceId": 12273351,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7734580,
     "sourceId": 12273663,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7734662,
     "sourceId": 12273807,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7734744,
     "sourceId": 12273954,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7734821,
     "sourceId": 12274094,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7734887,
     "sourceId": 12274232,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7735015,
     "sourceId": 12274450,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7735093,
     "sourceId": 12274596,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7735193,
     "sourceId": 12274759,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7735316,
     "sourceId": 12274923,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7735439,
     "sourceId": 12275109,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7735616,
     "sourceId": 12275375,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7735786,
     "sourceId": 12275615,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7736002,
     "sourceId": 12275962,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7736256,
     "sourceId": 12276351,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7736603,
     "sourceId": 12276835,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7736746,
     "sourceId": 12277031,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7747614,
     "sourceId": 12292652,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7753343,
     "sourceId": 12301073,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7759220,
     "isSourceIdPinned": true,
     "sourceId": 12315300,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7765705,
     "sourceId": 12320104,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7771570,
     "sourceId": 12328694,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7775840,
     "sourceId": 12335239,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31041,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": ".venv (3.9.6)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 37871.770514,
   "end_time": "2025-06-29T10:17:23.073100",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-06-28T23:46:11.302586",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
